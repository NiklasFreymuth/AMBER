<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="A supervised learning approach to iterative adaptive mesh generation using a hierarchical message passing network and automatic online labelling to progressively refine meshes toward an expert solution.">
  <meta property="og:title" content="AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction"/>
  <meta property="og:description" content="A supervised learning approach to iterative adaptive mesh generation using a hierarchical message passing network and automatic online labelling to progressively refine meshes toward an expert solution."/>
  <meta property="og:url" content="https://niklasfreymuth.github.io/AMBER/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="620"/>


  <meta name="twitter:title" content="AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction">
  <meta name="twitter:description" content="A supervised learning approach to iterative adaptive mesh generation using a hierarchical message passing network and automatic online labelling to progressively refine meshes toward an expert solution.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/banner_image.png">
  <meta name="twitter:card" content="Example 3d adaptive meshes generated by AMBER">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Adaptive Mesh Generation, Finite Element Method, Graph Neural Networks, Machine Learning, Computational Geometry">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <style>
  /* Target images inside the carousel to increase distance to caption (like a positive v-space!) */
  .results-carousel .item img {
    margin-bottom: 20px;
  }
  </style>
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Niklas Freymuth<sup>1</sup>,</span>
              <span class="author-block">
                Tobias Würth<sup>2</sup>,</span>
              <span class="author-block">
                Nicolas Schreiber<sup>1</sup>,</span>
              <span class="author-block">
                Balazs Gyenes<sup>1</sup>,</span>
              <span class="author-block">
                Andreas Boltres<sup>1,3</sup>,</span>
              <span class="author-block">
                Johannes Mitsch<sup>2</sup>,</span>
              <span class="author-block">
                Aleksandar Taranovic<sup>1</sup>,</span>
              <span class="author-block">
                Tai Hoang<sup>1</sup>,</span>
              <span class="author-block">
                Philipp Dahlinger<sup>1</sup>,</span>
              <span class="author-block">
                Philipp Becker<sup>1</sup>,</span>
              <span class="author-block">
                Luise Kärger<sup>2</sup>,</span>
              <span class="author-block">
                Gerhard Neumann<sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Autonomous Learning Robots, Karlsruhe Institute of Technology, Karlsruhe</span>
              <span class="author-block"><sup>2</sup>Institute of Vehicle System Technology, Karlsruhe Institute of Technology, Karlsruhe</span>
              <span class="author-block"><sup>3</sup>SAP SE</span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.23663.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/niklasfreymuth/AMBER" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.23663" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Schematic-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/amber_schematic.png" alt="Schematic overview of AMBER"/>
      <h2 class="subtitle has-text-centered">
        AMBER learns adaptive mesh generation on complex geometries from an expert dataset. <br>
        <b>Left</b>: During training, AMBER predicts a sizing field from expert-projected labels. <br>
        <b>Right</b>: During inference, AMBER iteratively predicts a sizing field, and feeds it into a mesh generator that uses the underlying geometry, until a final mesh MT is produced.
        </h2>
    </div>
  </div>
</section>
<!-- End Schematic -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The cost and accuracy of simulating complex physical systems using the Finite Element Method (FEM) scales with the resolution of the underlying mesh. Adaptive meshes improve computational efficiency by refining resolution in critical regions, but typically require task-specific heuristics or cumbersome manual design by a human expert. We propose Adaptive Meshing By Expert Reconstruction (AMBER), a supervised learning approach to mesh adaptation. Starting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e., a function mapping from the geometry to the local element size of the target mesh, and uses this prediction to produce a new intermediate mesh using an out-of-the-box mesh generator. This process is enabled through a hierarchical graph neural network, and relies on data augmentation by automatically projecting expert labels onto AMBER-generated data during training. We evaluate AMBER on 2D and 3D datasets, including classical physics problems, mechanical components, and real-world industrial designs with human expert meshes. AMBER generalizes to unseen geometries and consistently outperforms multiple recent baselines, including ones using Graph and Convolutional Neural Networks, and Reinforcement Learning-based approaches.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Method Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            We approach adaptive mesh generation as a supervised learning problem, factorizing the process into two key stages.
            First, a learnable model predicts a spatially-varying, scalar-valued sizing field.
            Second, a non-parametric mesh generator consumes this field to produce the final mesh.
            AMBER's central idea is to perform this prediction iteratively, allowing the model to gradually refine its own sampling resolution.
            Starting with a coarse, uniform mesh $M^0$, AMBER processes the corresponding graph to predict a vertex-level discrete sizing field.
            This collection of point-based predictions is then transformed into a smooth, continuous field using a linear interpolant, similar to a linear basis function in the FEM.
            The resulting continuous field then guides the generation of a new, more refined mesh, $M^{t+1}$.
          </p>
          <p>
            A single AMBER refinement step can be expressed as
          </p>
          <p>
            $$ M^{t+1} = g_\texttt{msh}\left(\Omega, \mathcal{I}_{M^t}\left(\sigma\left(\text{MPN}_{\theta}(G(M^t))\right)\right)\right)\text{.}$$
          </p>
          <p>
            Here, the current mesh $M^t$ is first converted into a graph representation $G(M^t)$.
            Our message passing network, $\text{MPN}_{\theta}$, processes this graph to predict vertex-level scalars, which are transformed into a discrete sizing field using some transformation $\sigma$.
            This discrete field is then transformed into a smooth, continuous field by a linear interpolant, $\mathcal{I}_{M^t}$.
            The mesh generator, $g_\texttt{msh}$, uses this continuous field to produce the refined mesh for the next iteration, $M^{t+1}$.
            This iterative loop and the flexibility of the underlying message passing network allow AMBER to progressively focus its resolution on the most critical regions of a provided arbitrary geometry.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Method Section -->

<!-- Qualitative results  -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Qualitative Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-quali1">
          <img src="static/images/amber_datasets.png" alt="Dataset Overview"/>
          <h2 class="subtitle has-text-centered">
            AMBER-generated meshes on six novel datasets for adaptive mesh generation.<br>
            The datasets include classical physics problems, mechanical components, and real-world industrial designs.
          </h2>
        </div>
        <div class="item item-quali1">
          <img src="static/images/results_fem.png" alt="Results on Poisson and Laplace"/>
          <h2 class="subtitle has-text-centered">
            AMBER-generated meshes on the Poisson and Laplace test domains.<br>
            Both tasks feature a FEM solution in the loop.
          </h2>
        </div>
        <div class="item item-quali2">
          <img src="static/images/results_no_fem.png" alt="Results on Airfoil, Console, Mold and Beam"/>
          <h2 class="subtitle has-text-centered">
            AMBER-generated meshes on the Airfoil, Console, Mold and Beam test domains.<br>
            Meshes are generated from the domain geometry to match an expert strategy.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End qualitative results -->



<!-- Quantitative results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Quantitative Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/quanti_main.png" alt="Main results comparing AMBER to baselines"/>
        <h2 class="subtitle has-text-centered">
          AMBER generates high-quality meshes on all datasets, outperforming recent image- and graph-based baselines.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/quanti_main.png" alt="Different Poisson mesh resolutions for AMBER, ASMR and the expert"/>
        <h2 class="subtitle has-text-centered">
          Estimated simulation error for different mesh resolutions on Poisson. <br>
          AMBER's meshes are on par with the expert that it learns from, while recent RL methods show worse performance and more variability. <br>
          AMBER can generalize to larger meshes during inference by scaling the predicted sizing field, maintaining mesh quality for over 100k elements.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End quantitative results -->








<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/AMBER_poster.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{freymuth2025amber,
          title={AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction},
          author={Freymuth, Niklas and W{\"u}rth, Tobias and Schreiber, Nicolas and Gyenes, Balazs and Boltres, Andreas and Mitsch, Johannes and Taranovic, Aleksandar and Hoang, Tai and Dahlinger, Philipp and Becker, Philipp and others},
          journal={arXiv preprint arXiv:2505.23663},
          year={2025}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>
